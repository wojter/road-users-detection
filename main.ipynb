{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wojter/road-users-detection/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Config"
      ],
      "metadata": {
        "id": "sPV8OfXSMQ6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "gqid_FbVMw1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# local or colab\n",
        "drive_mode = True\n",
        "\n",
        "# images scaled and packed in archive of var name @IMAGES_ARCHIVE\n",
        "archived_images = True"
      ],
      "metadata": {
        "id": "MvEdW7GTOlr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJqH4KM8y4Jo"
      },
      "outputs": [],
      "source": [
        "LABELS = [\n",
        "    {'name':'bike', 'id':1}, \n",
        "    {'name':'scooter', 'id':2},\n",
        "    {'name':'rolls', 'id':3},\n",
        "    {'name':'pedestrian', 'id':4},\n",
        "    {'name':'uto', 'id':5}\n",
        "]\n",
        "\n",
        "\n",
        "MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
        "#'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "#'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n",
        "\n",
        "IMAGE_WIDTH = 640\n",
        "IMAGE_HEIGHT = 640\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "NUM_STEPS = 10000\n",
        "NUM_EVAL_STEPS = 200\n",
        "CHECKPOINT_STEPS = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dy8PDo9Ljw7"
      },
      "outputs": [],
      "source": [
        "# folders\n",
        "\n",
        "# paths to images on instance \n",
        "IMAGES = os.path.join('images')\n",
        "IMAGES_TEST = os.path.join('images', 'test')\n",
        "IMAGES_TRAIN = os.path.join('images', 'train')\n",
        "\n",
        "TENSORFLOW_MODELS = os.path.join('external', 'tensorflow_models')\n",
        "DOWNLOADED_MODELS = os.path.join('external', 'downloaded_models')\n",
        "TF_RECORDS = os.path.join('external', 'tf_records')\n",
        "\n",
        "DRIVE_NAME = os.path.join('drive')\n",
        "GOOGLE_DRIVE = os.path.join(DRIVE_NAME, 'MyDrive')\n",
        "GOOGLE_DRIVE_COLAB = os.path.join(GOOGLE_DRIVE, 'COLAB')\n",
        "GOOGLE_DRIVE_IMAGES = os.path.join(GOOGLE_DRIVE, 'projects','images')\n",
        "IMAGES_ARCHIVE = os.path.join('archive.tar.gz')\n",
        "GOOGLE_DRIVE_IMG_ARCHIVE = os.path.join(GOOGLE_DRIVE, 'projects', IMAGES_ARCHIVE)\n",
        "\n",
        "# files\n",
        "LABEL_FILE = os.path.join('label_map.txt')\n",
        "TF_RECORD_FILE = os.path.join(TF_RECORDS, 'generate_tfrecord.py')\n",
        "TRAIN_RECORD = 'train.record'\n",
        "TEST_RECORD = 'test.record'\n",
        "VAL_RECORD = 'val.record'\n",
        "PIPELINE_CONFIG_PATH = 'model_config.config'\n",
        "TEST_CONFIG_PATH = 'test_model_config.config'\n",
        "\n",
        "FINE_TUNE_CHECKPOINT = os.path.join(DOWNLOADED_MODELS, MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "MODEL_DIR = os.path.join(GOOGLE_DRIVE, 'training') if drive_mode else os.path.join('training')\n",
        "BASE_CONFIG_PATH = os.path.join(TENSORFLOW_MODELS, 'research', 'object_detection', 'configs', 'tf2', f'{MODEL_NAME}.config')\n",
        "INFERENCE_GRAPH_DIR = os.path.join(GOOGLE_DRIVE_RESULTS, 'inference_graph')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Download and prepare required soft"
      ],
      "metadata": {
        "id": "fJ_9v4o_psoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if drive_mode:\n",
        "  from google.colab import drive\n",
        "  drive.mount(DRIVE_NAME)"
      ],
      "metadata": {
        "id": "lLAtYd6XMkWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get from github\n",
        "if not os.path.exists(TENSORFLOW_MODELS):\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models {TENSORFLOW_MODELS}\n",
        "if not os.path.exists(TF_RECORDS):\n",
        "  !git clone --depth 1  https://github.com/nicknochnack/GenerateTFRecord {TF_RECORDS}"
      ],
      "metadata": {
        "id": "J9aR3m8LXXSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRK24WfDlvwK"
      },
      "outputs": [],
      "source": [
        "if os.system(f\" \\\n",
        "cd { TENSORFLOW_MODELS }/research; \\\n",
        "protoc object_detection/protos/*.proto --python_out=.; \\\n",
        "cp object_detection/packages/tf2/setup.py .; \\\n",
        "python -m pip install .\") != 0:\n",
        "  raise Exception(\"Can't install Object Detection API\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run model builder test\n",
        "!python {TENSORFLOW_MODELS}/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "xthQxZrUYtJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "if tf.test.gpu_device_name() == '':\n",
        "    raise Exception('GPU IS MISSING')"
      ],
      "metadata": {
        "id": "74dKdPdVNKl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlWVJ4_02gM4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        assert tf.config.experimental.get_memory_growth(gpus[0])\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Images"
      ],
      "metadata": {
        "id": "a33711kVZX22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy images\n",
        "if drive_mode and archived_images:\n",
        "  !cd drive/MyDrive/projects/ && ls\n",
        "  !cp drive/MyDrive/projects/archive.tar.gz ./\n",
        "elif drive_mode and not archived_images:\n",
        "  !cp -r {GOOGLE_DRIVE_IMAGES} {IMAGES}"
      ],
      "metadata": {
        "id": "pRSyi2mRO6Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YmN51oIS0ga"
      },
      "outputs": [],
      "source": [
        "# unpack images if archived\n",
        "if drive_mode and archived_images:\n",
        "  if os.path.exists(IMAGES_ARCHIVE) and not os.path.exists(IMAGES):\n",
        "    !tar -zxvf {IMAGES_ARCHIVE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHymbRL2gMv"
      },
      "source": [
        "# 4. Labels and records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ1GNDGg2gMw"
      },
      "outputs": [],
      "source": [
        "with open(LABEL_FILE, 'w') as f:\n",
        "    for label in LABELS:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opjo2m8e2gMx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# tf record file generate\n",
        "!python {TF_RECORD_FILE} -x {IMAGES}/train -l {LABEL_FILE} -o {TRAIN_RECORD} \n",
        "!python {TF_RECORD_FILE} -x {IMAGES}/test -l {LABEL_FILE} -o {TEST_RECORD}\n",
        "!python {TF_RECORD_FILE} -x {IMAGES}/val -l {LABEL_FILE} -o {VAL_RECORD}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Model from object detection API"
      ],
      "metadata": {
        "id": "afw1gOM8itVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if Path(f\"{DOWNLOADED_MODELS}/{MODEL_NAME}.tar.gz\").is_file():\n",
        "    print(\"Model already exists\")\n",
        "else:\n",
        "    os.system('mkdir -p ' + DOWNLOADED_MODELS)\n",
        "    os.system(f\"cd {DOWNLOADED_MODELS}; wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL_NAME}.tar.gz\")\n",
        "    os.system(f\"cd {DOWNLOADED_MODELS}; tar -xf {MODEL_NAME}.tar.gz\")"
      ],
      "metadata": {
        "id": "8yOIBJG1itF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL5v57qv2gMz"
      },
      "source": [
        "## 6. Set config file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bfLVPSL2gM3"
      },
      "outputs": [],
      "source": [
        "# edit configuration file \n",
        "with open(BASE_CONFIG_PATH) as f:\n",
        "    config = f.read()\n",
        "with open('model_config.config', 'w') as f:\n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"', \n",
        "             'label_map_path: \"{}\"'.format(LABEL_FILE), config)\n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(FINE_TUNE_CHECKPOINT), config)\n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(TRAIN_RECORD), config)\n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(VAL_RECORD), config)\n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(len(LABELS)), config)\n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(BATCH_SIZE), config)\n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(NUM_STEPS), config)\n",
        "  # Set fine-tune checkpoint type to detection\n",
        "  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
        "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
        "  config = re.sub('max_detections_per_class: [0-9]+',\n",
        "                  'max_detections_per_class: {}'.format(100), config)\n",
        "  config = re.sub('max_total_detections: [0-9]+',\n",
        "                  'max_total_detections: {}'.format(100), config)\n",
        "  f.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzYIWep42gM4"
      },
      "outputs": [],
      "source": [
        "%cat {PIPELINE_CONFIG_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Training"
      ],
      "metadata": {
        "id": "58uSsxynvCJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python {TENSORFLOW_MODELS}/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n",
        "    --model_dir={MODEL_DIR} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={NUM_STEPS} \\\n",
        "    --checkpoint_every_n={CHECKPOINT_STEPS}"
      ],
      "metadata": {
        "id": "u4DUz-VDvE3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cz0iSy7E4lM"
      },
      "source": [
        "# 8. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypU46C0UE7tj"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "if drive_mode:\n",
        "  %tensorboard --logdir {MODEL_DIR}\n",
        "else:\n",
        "  %tensorboard --logdir {MODEL_DIR}/train --port=6006 --bind_all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python {TENSORFLOW_MODELS}/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n",
        "    --model_dir={MODEL_DIR} \\\n",
        "    --checkpoint_dir={MODEL_DIR}"
      ],
      "metadata": {
        "id": "R3egBWgDIPfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. After training"
      ],
      "metadata": {
        "id": "LLGzfAT2yl9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1 Save model"
      ],
      "metadata": {
        "id": "rg9aw1yJyrXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8oWT4bk2gM6"
      },
      "outputs": [],
      "source": [
        "!python {TENSORFLOW_MODELS}/research/object_detection/exporter_main_v2.py \\\n",
        "      --pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n",
        "      --trained_checkpoint_dir={MODEL_DIR} \\\n",
        "      --output_directory={INFERENCE_GRAPH_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2 Test model"
      ],
      "metadata": {
        "id": "0exetr6a6ORI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o69IlDag44Ot"
      },
      "outputs": [],
      "source": [
        "# edit configuration file \n",
        "with open(PIPELINE_CONFIG_PATH) as f:\n",
        "    config = f.read()\n",
        "with open(TEST_CONFIG_PATH, 'w') as f:\n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(TEST_RECORD), config)\n",
        "  f.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ece2LZNp6Ibf"
      },
      "outputs": [],
      "source": [
        "%cat {TEST_CONFIG_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wURUkzAa2gM6"
      },
      "outputs": [],
      "source": [
        "!python {TENSORFLOW_MODELS}/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={TEST_CONFIG_PATH} \\\n",
        "    --model_dir={MODEL_DIR} \\\n",
        "    --checkpoint_dir={MODEL_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E422Wqc0ew6G"
      },
      "source": [
        "#### 9.4 Convert model as json\n",
        "[converters](https://github.com/tensorflow/tfjs/tree/master/tfjs-converter)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "VQ4r8ZItzs5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A8DCnGjkGWW"
      },
      "outputs": [],
      "source": [
        "!tensorflowjs_converter \\\n",
        "    --input_format=tf_saved_model \\\n",
        "    --output_format=tfjs_graph_model \\\n",
        "    --signature_name=serving_default \\\n",
        "    --saved_model_tags=serve \\\n",
        "    {os.path.join(INFERENCE_GRAPH_DIR, 'saved_model')} \\\n",
        "    {os.path.join(INFERENCE_GRAPH_DIR, 'json_model')}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Visualize"
      ],
      "metadata": {
        "id": "p5F2kB1fIKrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "metadata": {
        "id": "y_2fTKGiUiEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs = config_util.get_configs_from_pipeline_file(os.path.join(INFERENCE_GRAPH_DIR, \"pipeline.config\"))\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(INFERENCE_GRAPH_DIR,'checkpoint', 'ckpt-0')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "metadata": {
        "id": "YKgsnG8pUkHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import object_detection\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils"
      ],
      "metadata": {
        "id": "PEprJU1iIJ-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(LABEL_FILE)\n",
        "category_index"
      ],
      "metadata": {
        "id": "MMAiwklwJbsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "imgExtension = [\"jpg\", \"jpeg\", \"png\"]\n",
        "def random_test_photo_path( folder_path):\n",
        "  allImg = list()\n",
        "  files = os.listdir(folder_path)\n",
        "  for img in files:\n",
        "    ext = img.split(\".\")[len(img.split(\".\"))-1]\n",
        "    if ext in imgExtension:\n",
        "      allImg.append(img)\n",
        "  choice = random.randint(0,len(allImg)-1)\n",
        "  return allImg[choice]"
      ],
      "metadata": {
        "id": "S7OygL1BD-67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_PATH = os.path.join(IMAGES_TEST, random_test_photo_path(IMAGES_TEST))\n",
        "img = cv2.imread(IMG_PATH)\n",
        "image_np = np.array(img)"
      ],
      "metadata": {
        "id": "YOFvAwFMLoIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detections.keys()"
      ],
      "metadata": {
        "id": "EouLpLNhHlM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "%matplotlib inline\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=10,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VCv8uA0xQ8KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternate display\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(image_np_with_detections)"
      ],
      "metadata": {
        "id": "PjjGnJKH-dA2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}