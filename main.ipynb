{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsVQ16+cNHR2ywcp2dco2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wojter/road-users-detection/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Config"
      ],
      "metadata": {
        "id": "sPV8OfXSMQ6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "import re"
      ],
      "metadata": {
        "id": "gqid_FbVMw1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# local or colab\n",
        "drive_mode = True\n",
        "\n",
        "# images scaled and packed in archive of var name @IMAGES_ARCHIVE\n",
        "archived_images = True"
      ],
      "metadata": {
        "id": "MvEdW7GTOlr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJqH4KM8y4Jo"
      },
      "outputs": [],
      "source": [
        "LABELS = [\n",
        "    {'name':'bike', 'id':1}, \n",
        "    {'name':'scooter', 'id':2},\n",
        "    {'name':'rolls', 'id':3},\n",
        "    {'name':'pedestrian', 'id':4},\n",
        "    {'name':'uto', 'id':5}\n",
        "]\n",
        "\n",
        "\n",
        "MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
        "#'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "#'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n",
        "\n",
        "IMAGE_WIDTH = 640\n",
        "IMAGE_HEIGHT = 640\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "NUM_STEPS = 10000\n",
        "NUM_EVAL_STEPS = 200\n",
        "CHECKPOINT_STEPS = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dy8PDo9Ljw7"
      },
      "outputs": [],
      "source": [
        "# folders\n",
        "\n",
        "# paths to images on instance \n",
        "IMAGES = os.path.join('images')\n",
        "IMAGES_TEST = os.path.join('images', 'test')\n",
        "IMAGES_TRAIN = os.path.join('images', 'train')\n",
        "\n",
        "TENSORFLOW_MODELS = os.path.join('external', 'tensorflow_models')\n",
        "DOWNLOADED_MODELS = os.path.join('external', 'downloaded_models')\n",
        "TF_RECORDS = os.path.join('external', 'tf_records')\n",
        "\n",
        "DRIVE_NAME = os.path.join('drive')\n",
        "GOOGLE_DRIVE = os.path.join(DRIVE_NAME, 'MyDrive')\n",
        "GOOGLE_DRIVE_COLAB = os.path.join(GOOGLE_DRIVE, 'COLAB')\n",
        "GOOGLE_DRIVE_IMAGES = os.path.join(GOOGLE_DRIVE, 'projects','images')\n",
        "IMAGES_ARCHIVE = os.path.join('archive.tar.gz')\n",
        "GOOGLE_DRIVE_IMG_ARCHIVE = os.path.join(GOOGLE_DRIVE, 'projects', IMAGES_ARCHIVE)\n",
        "\n",
        "# files\n",
        "LABEL_FILE = os.path.join('label_map.txt')\n",
        "TF_RECORD_FILE = os.path.join(TF_RECORDS, 'generate_tfrecord.py')\n",
        "TRAIN_RECORD = 'train.record'\n",
        "TEST_RECORD = 'test.record'\n",
        "VAL_RECORD = 'val.record'\n",
        "PIPELINE_CONFIG_PATH = 'model_config.config'\n",
        "\n",
        "FINE_TUNE_CHECKPOINT = os.path.join(DOWNLOADED_MODELS, MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "MODEL_DIR = os.path.join(GOOGLE_DRIVE, 'training') if drive_mode else os.path.join('training')\n",
        "BASE_CONFIG_PATH = os.path.join(TENSORFLOW_MODELS, 'research', 'object_detection', 'configs', 'tf2', f'{MODEL_NAME}.config')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Download and prepare required soft"
      ],
      "metadata": {
        "id": "fJ_9v4o_psoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if drive_mode:\n",
        "  from google.colab import drive\n",
        "  drive.mount(DRIVE_NAME)"
      ],
      "metadata": {
        "id": "lLAtYd6XMkWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get from github\n",
        "if not os.path.exists(TENSORFLOW_MODELS):\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models {TENSORFLOW_MODELS}\n",
        "if not os.path.exists(TF_RECORDS):\n",
        "  !git clone --depth 1  https://github.com/nicknochnack/GenerateTFRecord {TF_RECORDS}"
      ],
      "metadata": {
        "id": "J9aR3m8LXXSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRK24WfDlvwK"
      },
      "outputs": [],
      "source": [
        "if os.system(f\" \\\n",
        "cd { TENSORFLOW_MODELS }/research; \\\n",
        "protoc object_detection/protos/*.proto --python_out=.; \\\n",
        "cp object_detection/packages/tf2/setup.py .; \\\n",
        "python -m pip install .\") != 0:\n",
        "  raise Exception(\"Can't install Object Detection API\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run model builder test\n",
        "!python {TENSORFLOW_MODELS}/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "xthQxZrUYtJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "if tf.test.gpu_device_name() == '':\n",
        "    raise Exception('GPU IS MISSING')"
      ],
      "metadata": {
        "id": "74dKdPdVNKl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlWVJ4_02gM4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        assert tf.config.experimental.get_memory_growth(gpus[0])\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Images"
      ],
      "metadata": {
        "id": "a33711kVZX22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy images\n",
        "if drive_mode and archived_images:\n",
        "  !cd drive/MyDrive/projects/ && ls\n",
        "  !cp drive/MyDrive/projects/archive.tar.gz ./\n",
        "elif drive_mode and not archived_images:\n",
        "  !cp -r {GOOGLE_DRIVE_IMAGES} {IMAGES}"
      ],
      "metadata": {
        "id": "pRSyi2mRO6Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YmN51oIS0ga"
      },
      "outputs": [],
      "source": [
        "# unpack images if archived\n",
        "if drive_mode and archived_images:\n",
        "  if os.path.exists(IMAGES_ARCHIVE) and not os.path.exists(IMAGES):\n",
        "    !tar -zxvf {IMAGES_ARCHIVE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHymbRL2gMv"
      },
      "source": [
        "# 4. Labels and records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ1GNDGg2gMw"
      },
      "outputs": [],
      "source": [
        "with open(LABEL_FILE, 'w') as f:\n",
        "    for label in LABELS:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opjo2m8e2gMx",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# tf record file generate\n",
        "!python {TF_RECORD_FILE} -x {IMAGES}/train -l {LABEL_FILE} -o {TRAIN_RECORD} \n",
        "!python {TF_RECORD_FILE} -x {IMAGES}/test -l {LABEL_FILE} -o {TEST_RECORD}\n",
        "!python {TF_RECORD_FILE} -x {IMAGES}/val -l {LABEL_FILE} -o {VAL_RECORD}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Model from object detection API"
      ],
      "metadata": {
        "id": "afw1gOM8itVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if Path(f\"{DOWNLOADED_MODELS}/{MODEL_NAME}.tar.gz\").is_file():\n",
        "    print(\"Model already exists\")\n",
        "else:\n",
        "    os.system('mkdir -p ' + DOWNLOADED_MODELS)\n",
        "    os.system(f\"cd {DOWNLOADED_MODELS}; wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL_NAME}.tar.gz\")\n",
        "    os.system(f\"cd {DOWNLOADED_MODELS}; tar -xf {MODEL_NAME}.tar.gz\")"
      ],
      "metadata": {
        "id": "8yOIBJG1itF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL5v57qv2gMz"
      },
      "source": [
        "## 6. Set config file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bfLVPSL2gM3"
      },
      "outputs": [],
      "source": [
        "# edit configuration file \n",
        "with open(BASE_CONFIG_PATH) as f:\n",
        "    config = f.read()\n",
        "with open('model_config.config', 'w') as f:\n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"', \n",
        "             'label_map_path: \"{}\"'.format(LABEL_FILE), config)\n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(FINE_TUNE_CHECKPOINT), config)\n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(TRAIN_RECORD), config)\n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', \n",
        "                  'input_path: \"{}\"'.format(VAL_RECORD), config)\n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(len(LABELS)), config)\n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(BATCH_SIZE), config)\n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(NUM_STEPS), config)\n",
        "  # Set fine-tune checkpoint type to detection\n",
        "  config = re.sub('fine_tune_checkpoint_type: \"classification\"', \n",
        "             'fine_tune_checkpoint_type: \"{}\"'.format('detection'), config)\n",
        "  config = re.sub('max_detections_per_class: [0-9]+',\n",
        "                  'max_detections_per_class: {}'.format(100), config)\n",
        "  config = re.sub('max_total_detections: [0-9]+',\n",
        "                  'max_total_detections: {}'.format(100), config)\n",
        "  f.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzYIWep42gM4"
      },
      "outputs": [],
      "source": [
        "%cat {PIPELINE_CONFIG_PATH}"
      ]
    }
  ]
}